{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib\n",
    "from scipy.fftpack import fft\n",
    "from math import pow\n",
    "from pykalman import KalmanFilter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess \n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_bessellow():\n",
    "    \n",
    "    raw_signal = acc_read_variable[\"ax\"]\n",
    "    d, c = signal.bessel(3, 0.03, 'low', analog=False, norm='phase')\n",
    "    result = signal.filtfilt(d, c, raw_signal)\n",
    "    \n",
    "    return result\n",
    "\n",
    "#lowess filter\n",
    "def loweesfilter():\n",
    "    \n",
    "    low_smooth = lowess(acc_read_variable[\"ax\"], np.arange(acc_read_variable[\"time\"].shape[0]), frac=0.01)\n",
    "    \n",
    "    return low_smooth\n",
    "\n",
    "def kalmanfileter(): \n",
    "    \n",
    "    # Read read_variable\n",
    "    var_a = acc_read_variable[[\"ax\"]].values\n",
    "    kf = KalmanFilter(initial_state_mean=0, n_dim_obs=1)\n",
    "    kf = kf.em(var_a, n_iter=5)\n",
    "    (filtered_state_means, filtered_state_covariances) = kf.filter(acc_read_variable[\"ax\"])\n",
    "    \n",
    "    return kf\n",
    "\n",
    "def mlp_regressor():\n",
    "    \n",
    "    X_train, X_valid,y_train, y_valid = train_test_split(X,y)\n",
    "    model = MLPRegressor(hidden_layer_sizes=(8, 6), activation='logistic', solver='lbfgs')\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model.score(X_train, y_train))\n",
    "    print(model.score(X_valid, y_valid))\n",
    "    \n",
    "def random_forest_classifier():\n",
    "    \n",
    "    X_train, X_valid,y_train, y_valid = train_test_split(X,y)\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=3, min_samples_leaf=10)                  \n",
    "    model.fit(X_train,y_train)\n",
    "    model.score(X_valid, y_valid)\n",
    "    y_predict = model.predict(X_valid)\n",
    "    \n",
    "def gaussian_nb():\n",
    "    \n",
    "    X_train, X_valid,y_train, y_valid = train_test_split(X,y)\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_valid)\n",
    "    print(model.score(X_train, y_train))\n",
    "    print(model.score(X_valid, y_valid))\n",
    "    print(accuracy_score(y_valid, y_predict))\n",
    "    \n",
    "def kneighborsclassifier():\n",
    "   \n",
    "    X_train, X_valid,y_train, y_valid = train_test_split(X,y)\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_valid)\n",
    "    print(model.score(X_train, y_train))\n",
    "    print(model.score(X_valid, y_valid))\n",
    "    print(accuracy_score(y_valid, y_predict))\n",
    "        \n",
    "def voting_classifier():\n",
    "    \n",
    "    X_train, X_valid,y_train, y_valid = train_test_split(X,y)\n",
    "    model = VotingClassifier([\n",
    "        ('nb', GaussianNB()),\n",
    "        ('knn', KNeighborsClassifier(5)),\n",
    "        ('svm', SVC(kernel='linear', C=0.1)),\n",
    "        ('tree1', DecisionTreeClassifier(max_depth=4)),\n",
    "        ('tree2', DecisionTreeClassifier(min_samples_leaf=10)),\n",
    "    ])\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_valid)\n",
    "    print(model.score(X_train, y_train))\n",
    "    print(model.score(X_valid, y_valid))\n",
    "    print(accuracy_score(y_valid, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
